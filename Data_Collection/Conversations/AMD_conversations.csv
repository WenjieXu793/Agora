Conversation,Date
"@Dair Sansyzbayev - ""... what is the way out here?""Products matter. Money follows. Technology is the product at AMD. Ignore tech at your peril.",2024-10-06
"@Dair Sansyzbayev You can model the way finbox.com does it.  They use 5-7 different models and then do an average or median. They also do peer benchmarks. But at the end of the day,  there should always be a range. Optimistic and pessimistic. JMHO",2024-10-06
"Author - ""Despite AMD's weak competitive position against Nvidia...""Where the hell did I leave my bear spray? AMD has a clear competitive advantage over NVDA. In case you missed it...How does Nvidia's multi-chip design compare to AMD's chiplets?First a little background. In the old days node shrink was the driving force to achieve more compute. This became known as Moore's Law which says the number of transistors in a chip roughly doubles every two years with minimal cost increase. Decades passed with massive increase in compute while cost essentially stayed the same. Unfortunately nothing lasts forever. Transistors continue getting smaller but at increased cost and difficulty.Multi-chip (MC) design and chiplet design both seek to maximize compute in response to the diminishing returns of Moore's Law. As each design technique is pressed to its limit the distinction between them sometimes becomes blurry. But there are hallmarks which distinguish MC from chiplets.Described simply, MC combines two or more chips together in a single package while leaving the design quite similar to what each chip would be if packaged as a stand-alone unit. Each chip has a monolithic design. That's the hallmark of MC. The term monolithic literally translates as ""one stone"". This means all functionality necessary is contained on the chip to make it self-sufficient. Monolithic design is a consequence of Moore's Law. As ever more transistors become available there is an incentive to aggregate more functionality and performance into one chip.But cramming all that capability into a single chip has made monolithic chips physically bigger. High performance monolithic designs tend to be quite large. Nvidia's Blackwell is an MC design. The package contains eight stacks of 24GB HBM plus two 800mm² monolithic GPU chips. Each GPU chip is at the reticle size limit. Which implies those GPU chips can't get any bigger due to optical limitations of lithography. Designing chips of such size is problematic as nodes continue to shrink. Smaller transistors provide more targets for defects in a given area. Large chips have more area and thus greater opportunity for a defect to wipe out a chip.There's also a dire issue looming ahead. Chip lithography will soon reach optical limits which demand a reduction in reticle size. Specifically this happens when the node process gets smaller than 1.8nm. At that point high numerical aperture (high-NA) EUV becomes a necessity. It has only half the reticle size of current EUV. Thus staying with monolithic design would force existing functionality into half the space. Even though node shrink will make more transistors available, the abrupt reduction in reticle size will be a severe restriction for chip designers. Any design which relies on a large chip to provide sufficient compute power will be in trouble.In the near term Nvidia might just keep doubling and tripling down on MC design. Rubin will likely be MC because the node process is 3nm and thus doesn't suffer from reticle size reduction which only happens below 1.8nm nodes. In the longer term MC design will be confronted with integrating lots of much smaller chips. Almost sounds like chiplets.Chiplets are an alternative to MC design. However it's not simply connecting a bunch of smaller monolithic chips. Neither is it busting up a large monolithic chip into pieces and stitching them back together. Chiplets are about functional disaggregation of traditional monolithic chip design. It has to be done thoughtfully from the ground up. Anything less won't work which is why INTC's Ponte Vecchio (PV) sucks. According to Jim Keller PV is just a monolithic design divided into pieces called tiles and stitched together with EMIB (2.5D) and Foveros (3D) packaging. So INTC really doesn't understand chiplets even though they probably believe otherwise. But proof is in the results. PV in Aurora will use 3x more power for the same compute as MI300A in El Capitan. That's a staggering difference in performance. Obviously AMD has a lead on INTC with NVDA even further behind the chiplet learning curve. Chiplets are not easy. PV is dead on arrival because INTC implemented chiplets poorly.So let's talk about chiplets done right. AMD began the chiplet journey years ago with Zen. It started with baby steps and was an evolutionary process. First Zen EPYC server CPU Naples was actually an MC design composed of four 8-core Zeppelin dies. Each Zeppelin die was a self-contained monolithic chip with compute, IO, and a homegrown interconnect called Infinity Fabric. AMD packaged those monolithic chips into an unprecedented 32-core server CPU at a reasonable price. Beauty of Zen was not skin deep. Those Zeppelin dies could be packaged as one die for Ryzen, two dies for Ryzen Threadripper, or four dies for EPYC. AMD used a modular chip design to attack INTC in mainstream desktop, high-end desktop, and performance server markets. It was an audacious strategy where one AMD chip challenged many INTC chips across three markets. In response INTC released a statement dismissing AMD as gluing chips together. Denial is the first stage of grief.AMD's Zen 2 product Rome was a true chiplet design. Functional separation is the hallmark. In this case IO and compute were put on different dies. Disaggregated design had a distinct advantage. It allowed AMD to use 7nm for compute and 14nm for IO. Scarce allocation of the more expensive 7nm node at TSMC could be dedicated to compute dies for higher performance. While a less expensive 14nm node from GlobalFoundries made the IO die. What's interesting is IO performance didn't suffer because IO circuitry is less demanding.Zen 3 Milan followed Rome with double the compute cores, optional disaggregated 3D V-Cache, and improved Infinity Fabric which reduced inter-core latency. Milan-X used SoIC for the 3D V-Cache. At this time AMD also pushed Instinct GPU into the limelight with MC designed MI250X for Frontier. Milan and MI250X won the exascale project over traditional contenders like IBM, INTC, and NVDA. In the past, lilliputian AMD competed with behemoths IBM and INTC to sometimes win the CPU for supercomputer projects. But no matter who won the CPU it was NVDA that always provided GPU if this was also needed. With Frontier AMD won both CPU and GPU in a clean sweep. Remarkably GPU performs over 99% of compute in Frontier. Thus winning Frontier was a milestone for the Zen-like ascendance of AMD's long dormant GPU. An interesting aside is GPU MI250X has an MC design just like CPU Naples. AMD is running the same Zen-like playbook in GPU as it did in CPU. Frontier got the ball rolling for AMD's GPU renaissance. It's a feather in the cap for AMD.Zen 4 Genoa came next and offered even more cores. Including compact Zen 4c cores for Bergamo and Siena. Infinity Fabric evolved into Infinity Architecture which enabled CPU-GPU coherency for long sought Heterogeneous System Architecture (HSA). This will have important implications for the future as AMD adds more goodies to their chiplet designs. AMD also reused CPU core chiplet dies (CCDs) from Genoa in chiplet designed Instinct MI300A to win their second exascale project El Capitan. So following AMD's Zen-like playbook, development of the MI300 series is much like Rome as both are the first chiplet designs in their respective domains. Winning El Capitan vindicates AMD's versatile and effective chiplet technology by doubling the performance of what previous generation Frontier does. Meanwhile INTC's power hog PV in Aurora finally reached exascale performance in May. But struggling Aurora is still limping along at half capacity while burning massive power and hasn't yet matched smaller Frontier.Much has changed since the dark days before Zen. AMD is stronger now and seeking AI greenfield opportunity. Notably the chiplet design of MI300A for El Capitan enabled the rapid deployment of MI300X early this year as a variant to address the booming AI market. Upgrade MI325X arrives later this year and MI350X comes next year. AI beast MI400 is scheduled for release in 2026.At this point INTC is seriously wobbling. NVDA is feeling competition for the first time with AMD's Instinct. Recent setback of Blackwell reveals stress at NVDA in response to pressure from AMD. Monolithic design of NVDA products will have difficulty competing with the more nimble and flexible chiplet design paradigm used by AMD. While NVDA might compete awhile using MC and fast interconnect that won't hold for long. AMD already has fast interconnect as demonstrated in exascale supers Frontier and El Capitan. Industry heavyweights are joining AMD to adopt Ultra Accelerator Link (UALink) based on Infinity Fabric and combining it with ultra-Ethernet. This new industry standard will transform NVDA's proprietary fortress into a prison for their customers. Folks will be jumping from the Infiniband walls and swimming the CUDA moat to get out.AMD's roadmap for CPU and GPU looks good. Clearly chiplet design when done right is very powerful. In retrospect it's now obvious that INTC's fate was sealed the moment they dismissed chiplets. INTC's hubris and arrogance doomed them.NVDA seems to be making the same mistake.",2024-10-06
"The origins of discounted cash flow (DCF) models can be traced back to ancient times, when interest was first charged on loans. The idea of discounting future cash flows is similar to techniques used in ancient Egyptian and Babylonian mathematics.DCF models should be combined with other models and averaged. Never use this in isolation, especially on high growth Companies. Otherwise your just playing tricks on yourself.",2024-10-06
"""There are three strong indications of AMD's substantial overvaluation: sky-high valuation ratios, ""finviz.com/...Forward P/E	31.15As of now, the current Price-to-Earnings (P/E) ratio for the S&P 500 is approximately 30.02""and extremely aggressive insider selling from Lisa Su.""Preplanned sells and option exercise are normal and good signs.The accuracy of Discounted Cash Flow (DCF) estimates for AMD over the last 5 years has been mixed. Volatility and Growth: AMD has experienced significant growth and volatility in its earnings and cash flows, making it challenging to accurately predict future cash flows using the DCF model.Market Conditions: Changes in market conditions, competition, and technological advancements have also impacted AMD’s performance, affecting the reliability of DCF estimates.DCF Limitations: The DCF model has inherent limitations, especially for companies with high growth rates and unpredictable cash flows like AMD.Overall, while DCF can provide a rough estimate of AMD’s intrinsic value, it may not always be accurate due to the factors mentioned above.",2024-10-06
"Author - ""I hope that the DCF model will help me to solidify my position about AMD's overvaluation.""A tragic echo of former ""greats"" like Michael Wiggins De Oliveira and Mark Hibben. Those two totally missed AMD's rise from near extinction to clobber INTC. They focused on the wrong stuff. Now Dair is on a similar path regarding AMD and NVDA.Dair, put down the DCF crack pipe. Get some fresh air. Buy AMD and hold for 2 years. Just an opinion.",2024-10-06
"@stocks for profit You're obviously a tech guy analyzing the tech of 2 tech companies... But here's the guy who wrote this piece: ""I am a highly experienced Chief Financial Officer (CFO) with a strong background in the oilfield and real estate industries"".  That's why he could write sentences like this:  ""Seasonality trends appear unfavorable for AMD in October, with the stock achieving gains in only 40% of cases over the last ten years.""Personally, I'm more interested in reading about the technology of both companies & how they differ, when the story is about a competition between two tech companies for primacy in this field IN THE FUTURE.  No disrespect to the author, but the technology, to me, is more important than the last ten years of October returns.",2024-10-06
"In case you missed it...From a chip design perspective NVDA's Blackwell is not impressive. Two reticle-sized monolithic dies lashed together pushes a tired chip design philosophy to the breaking point. Blackwell's 2.27x performance gain over H100 comes mostly from doubling down on the huge dies. After backing out this doubling effect what's left is a 14% improvement per die.https://tinyurl.com/44z94v5r (AnandTech - NVIDIA Blackwell Architecture - 3/18/2024)Almost half of that 14% gain is due to TMSC's N4P node for Blackwell versus N4 for H100. Both N4 and N4P are actually members of the TSMC 5 nm process family. Though Jensen tends to omit this detail in all his hype. N4P offers 11% better performance to N5 while N4 has only 5%. So knock 6% off the 14% gain with the remainder due to enhancements from NVDA's illustrious chip design team. That 8% is not much to crow about. But pesky math won't stop Jensen from more chest thumping.https://tinyurl.com/mry9zzys (TSMC - N4P Process - 10/26/2021)In any event NVDA took their best shot and it was lackluster. Blackwell will be clobbered by the MI350 series in 2025 with CDNA 4 having a 35x increase in performance compared to MI300X's CDNA 3. But before then there's MI325X in Q4 with 288GB of HBM3E and 1.3x more performance than competitive offerings. That should minimize any advantage claimed by NVDA when Blackwell is released in Q4 2024 or Q1 2025. Blackwell gets only a brief moment in the sun before it is eclipsed.https://tinyurl.com/2s37nzjx (AnandTech - AMD Lays Out Accelerator Roadmap to 2026 - 6/2/2024)Things don't look better for Rubin either. It's dead on arrival when facing MI400. NVDA's lack of proficiency in chiplets dooms Rubin in 2026 to be a double or triple down version of Blackwell. Assuming the problem with CoWoS-L gets fixed, expect four or six giant reticle-sized monolithic dies lashed together ad nauseam. In this case more is not better because it uses lots of power. This increases operating expenses. Huge dies are also vulnerable to defects. Thus the low yield makes them pricey. Jensen just passes the cost on to the customer. Folks will be eager for alternatives from AMD.Meanwhile NVDA will be spending billions designing the same lame stuff again and again.",2024-10-06
"Title - ""AMD: Overvalued In The Shadow Of Nvidia""Better - ""AMD: Undervalued Stepping Out From Nvidia's Shadow""There, fixed it for you.",2024-10-06
"Author - ""... Nvidia invested $10 billion on developing its brand-new Blackwell GPU.""NVDA stumbles and blows billions on obsolete monolithic chip design.Meanwhile AMD diligently executes a chiplet strategy for their MI series roadmap. MI300X was released in January of this year while MI325X will debut before year end. MI350X arrives next year and MI400 comes in 2026. NVDA has never faced competition and relies on monopoly power. Successive generations of AMD products will destroy NVDA's business model.Value of a dollar is not lost on Lisa. AMD developed Zen on a shoestring budget and kicked INTC's a$$. INTC is wobbling. NVDA is next. AMD is stronger now and seeking AI greenfield opportunity. NVDA is on the same road as INTC. We know where it leads. Expect a more evenly split market in two years.Spending wisely is more important than spending wildly.",2024-10-06
"@SuperPac:  Presuming Powell / the Fed continues to be DATA based (AKA rational) about their moves, that's the best we can have. For example, ongoing evidence we aren't entering a recession (if the recent jobs data is a valid indication) should preclude ""too many"" rate cuts. I believe the experts at the Fed are MUCH more competent to make such decisions than a bazillion armchair pundits and political hacks that infest the internet with their emotional policy opinions, but few facts and VERY little actual math and economics.  That's why I never say ""the Fed should do X short term"".  Having lived through the inflation storm of the late 60's through early 80's, preventing anything close to THAT is job one by a country mile for the fed, IMO.",2024-10-06
"There are a slew of second and third best competitors that made their investors wealthy.  Two of the keys to any investment are timing and beneficial price at the times of purchase and sale.  Hit those, and you don’t have to worry too much about who the best is…",2024-10-06
"Everything in the world is overvalued and inflated. I’m finally up on my AMD position so my imaginary worry has now shifted to what to do with my profits when it goes to $200 again. I’ll say it one more time; our only job is to make money in the markets, not worry about a stock being overvalued with positive momentum. Actually I would rather worry more about supply and demand. Isn’t that what really moves stock prices up or down?",2024-10-06
"Great analysis Dair! “Despite AMD's competitive weaknesses, its stock price has doubled since January 2023, potentially buoyed by Nvidia's performance and strong investor support”Agreed! Despite the rising demand in a strategic industry like semiconductors, AMD is a clear looser. $NVDA leads the way, $TSM is the global foundry. They’re the 2 best large-cap stocks overall with an impressive competitive advantage, sustainable over time, and a big growth potential, considering that, in this industry, demand largely exceeds the supply.Buy winners and hold them for the long haul!",2024-10-06
"@stocks for profit Frontier supercomputer uses 100 gallons per second for water cooling.I think in the end AMD will water cool too, this would allow AMD to move up to the same 1200 Watts with less TCO than NVDA after NVDA normalizes the water requirement.Air cooling in VWs and motorcycles gave way to water as HP climbed on heat transfer needs.Total Cost of Ownership (TCO) ComparisonAMD MI300XPower Consumption: Approximately 750 watts per GPU.Cooling Efficiency: Liquid-cooled systems can save over 35% in energy consumption compared to air-cooled systems.TCO Savings: Liquid cooling can lead to over 51% data center energy cost savings.NVIDIA BlackwellPower Consumption: Ranges from 700 to 1,200 watts per GPU.Cooling Efficiency: Liquid cooling is essential due to high power consumption, with systems like the GB200 NVL72 consuming up to 140 kW per rack.TCO Savings: Liquid cooling can significantly reduce energy costs, but exact savings depend on the specific configuration and usage.SummaryEnergy Efficiency: Both systems benefit significantly from liquid cooling, with AMD MI300X showing slightly better energy efficiency.Cost Savings: Both systems offer substantial TCO savings with liquid cooling, but the exact difference would depend on the specific deployment and operational conditions.",2024-10-06
"@Sighcopath - ""... new AMD GPU for server and AI farms.... Do they run cooler than the NVDA GPU that need water cooling... if a leak happens on an upper tier processor?""AMD has prioritized energy efficiency so air cooling seems likely. Water cooling is a big expensive deal. Air cooling simplifies operation and reduces TCO. Energy efficiency will help AMD gain market share.As for when an NVDA server springs a leak on an upper tier expect some fireworks even with a quick cutoff. Maybe Jensen should pack those racks with super absorbent non-flammable kitty litter. ;-)",2024-10-06
"Author - ""As communicated by the company, the CDNA 4 will power their MI350 series set to be released in 2025, and CDNA 5 will be featured in the MI400 series in 2026.""AMD says MI400 will feature ""CDNA Next"" rather than CDNA 5. This seems like a deliberate distinction which could have important implications. AMD recently announced their intention to merge CDNA with RDNA to make a unified UDNA GPU architecture. Unification will increase AMD's AI market penetration by including products used for gaming. Growing AI developer mindshare is paramount. There's way more folks owning gaming GPUs than dedicated AI machines. AMD must do this to be competitive.MI400 was originally scheduled for 2025 before MI350 took that slot. Conceivably a 2026 release for MI400 gives AMD sufficient time to include UDNA in its design. Regardless, MI500 will definitely have UDNA in 2027.",2024-10-06
"@ET180 - ""... inference has been based on large matrix multiplication many times.""Apparently the cost of AI inference with machines from Cerebras Systems (CS) is too high. Only a few very deep pockets can afford them. See link and quote below...https://tinyurl.com/3jw6vnpd (Next Platform - Cerebras Goes Hyperscale - 3/14/2024)""The one thing that Cerebras also does not do, except for unnamed three letter agencies that we can’t talk about, is AI inference. The CS machines are for AI training only unless you are Uncle Sam. And so, to bring the cost of inference down, which is high, Cerebras is partnering with Qualcomm on its Cloud AI 100 accelerator to provide a complete training and inference hardware stack.""How well this partnership with Qualcomm works remains to be seen. In the mean time the Cerebras Wafer Scale Engine (WSE) processor is best suited for AI training. But WSE only has FP16 even though FP8 is becoming popular for AI. Data formats are not the only thing in flux. AI models will likely continue to change significantly. Cerebras WSE processors might not be sufficiently adaptable. See quote below.""With the WSE compute engines, you don’t have FP64 support with the CS systems, and you can’t do anything else with them, either. Like you really can’t with a Google TPU, either. That is the price you are paying for the Nvidia software stack and a more general purpose compute engine.""So Cerebras doesn't have enough general compute capability to do any other job effectively. There's no high precision for HPC. Training of AI models as currently conceived is the only thing it's good at. While matrix math for AI will likely always be necessary that might not be sufficient as models evolve. WSE lacks the flexibility of a GPU for future-proofing.Cerebras machines are optimized for the present AI paradigm. This makes them brittle.",2024-10-06
"When you run out of ideas go big.Cerebras is an example of that. Hugeness is often impressive. Same could be said about dinosaurs. Cerebras tech takes 2D semi to the limit with wafer scale. Size is the last phase of innovation. Aside from scale, the Cerebras machine is FP16 and relies heavily on sparsity for high performance. You can't do anything else with a Cerebras machine other than massive matrix math to implement the current conception of AI.Future of semi is 3D. AI models will evolve. GPU is flexible. Cerebras isn't.",2024-10-05
@geekinasuit Excellent!  I've been adding to my position since 1st purchase of $141.00.  I firmly and confidently believe AMD will surpass previous high of $227 before end of year !!,2024-10-05
