{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('../final_dataset.csv', index_col=0)\n",
    "training_df = training_df.dropna()\n",
    "ground_truth = training_df['Buy']\n",
    "training_df = training_df.drop(['Symbol', 'beta', 'profitMargins','Name', 'Analyst', 'agora_pred'],\n",
    "                          axis=1)\n",
    "X = training_df[['headline_polarity', 'convo_polarity','forwardEps','bookValue', 'heldPercentInstitutions', \n",
    "        'shortRatio', 'shortPercentOfFloat']]\n",
    "y = training_df['Buy'].values.ravel()\n",
    "\n",
    "X2 = training_df[['headline_polarity', 'convo_polarity','forwardEps','bookValue', 'heldPercentInstitutions', \n",
    "        'shortRatio', 'shortPercentOfFloat', 'last2PolarityDeltaConvo', 'last2PolarityDeltaHead']]\n",
    "y2 = training_df['Buy'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (688, 7)\n",
      "X_test size: (172, 7)\n",
      "y_train size: (688,)\n",
      "y_test size: (172,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.50      0.59        36\n",
      "           1       0.88      0.95      0.91       136\n",
      "\n",
      "    accuracy                           0.85       172\n",
      "   macro avg       0.80      0.72      0.75       172\n",
      "weighted avg       0.84      0.85      0.84       172\n",
      "\n",
      "[[ 18  18]\n",
      " [  7 129]]\n",
      "Log Loss: 5.238903108883307\n",
      "X_train size: (688, 7)\n",
      "X_test size: (172, 7)\n",
      "y_train size: (688,)\n",
      "y_test size: (172,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.56      0.68        36\n",
      "           1       0.89      0.98      0.93       136\n",
      "\n",
      "    accuracy                           0.89       172\n",
      "   macro avg       0.88      0.77      0.81       172\n",
      "weighted avg       0.89      0.89      0.88       172\n",
      "\n",
      "[[ 20  16]\n",
      " [  3 133]]\n",
      "Log Loss: 3.9815663627513134\n",
      "X_train size: (688, 7)\n",
      "X_test size: (172, 7)\n",
      "y_train size: (688,)\n",
      "y_test size: (172,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.38      0.51        37\n",
      "           1       0.85      0.97      0.91       135\n",
      "\n",
      "    accuracy                           0.84       172\n",
      "   macro avg       0.81      0.67      0.71       172\n",
      "weighted avg       0.83      0.84      0.82       172\n",
      "\n",
      "[[ 14  23]\n",
      " [  4 131]]\n",
      "Log Loss: 5.658015357593971\n",
      "X_train size: (688, 7)\n",
      "X_test size: (172, 7)\n",
      "y_train size: (688,)\n",
      "y_test size: (172,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.49      0.58        37\n",
      "           1       0.87      0.95      0.91       135\n",
      "\n",
      "    accuracy                           0.85       172\n",
      "   macro avg       0.80      0.72      0.74       172\n",
      "weighted avg       0.84      0.85      0.84       172\n",
      "\n",
      "[[ 18  19]\n",
      " [  7 128]]\n",
      "Log Loss: 5.44845923323864\n",
      "X_train size: (688, 7)\n",
      "X_test size: (172, 7)\n",
      "y_train size: (688,)\n",
      "y_test size: (172,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.57        37\n",
      "           1       0.87      0.92      0.90       135\n",
      "\n",
      "    accuracy                           0.83       172\n",
      "   macro avg       0.75      0.72      0.73       172\n",
      "weighted avg       0.82      0.83      0.82       172\n",
      "\n",
      "[[ 19  18]\n",
      " [ 11 124]]\n",
      "Log Loss: 6.077127606304636\n",
      "Average Accuracy: 0.8535\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]  \n",
    "    \n",
    "    print(\"X_train size:\", X_train.shape)\n",
    "    print(\"X_test size:\", X_test.shape)\n",
    "    print(\"y_train size:\", y_train.shape)\n",
    "    print(\"y_test size:\", y_test.shape)\n",
    "    \n",
    "    y_train_distribution = Counter(y_train)\n",
    "    y_test_distribution = Counter(y_test)\n",
    "\n",
    "    print(\"\\ny_train distribution:\", y_train_distribution)\n",
    "    print(\"y_test distribution:\", y_test_distribution)\n",
    "\n",
    "    y_train_percent = {k: v / len(y_train) * 100 for k, v in y_train_distribution.items()}\n",
    "    y_test_percent = {k: v / len(y_test) * 100 for k, v in y_test_distribution.items()}\n",
    "\n",
    "    print(\"\\nClass distribution in y_train (percentages):\", y_train_percent)\n",
    "    print(\"Class distribution in y_test (percentages):\", y_test_percent)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(f'Log Loss: {log_loss(y_test, predictions)}')\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (800, 20)\n",
      "X_test size: (200, 20)\n",
      "y_train size: (800,)\n",
      "y_test size: (200,)\n",
      "\n",
      "y_train distribution: Counter({1: 400, 0: 400})\n",
      "y_test distribution: Counter({1: 100, 0: 100})\n",
      "\n",
      "Class distribution in y_train (percentages): {1: 50.0, 0: 50.0}\n",
      "Class distribution in y_test (percentages): {1: 50.0, 0: 50.0}\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       100\n",
      "           1       0.91      0.85      0.88       100\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.88       200\n",
      "weighted avg       0.89      0.89      0.88       200\n",
      "\n",
      "[[92  8]\n",
      " [15 85]]\n",
      "Log Loss: 4.145020139748473\n",
      "X_train size: (800, 20)\n",
      "X_test size: (200, 20)\n",
      "y_train size: (800,)\n",
      "y_test size: (200,)\n",
      "\n",
      "y_train distribution: Counter({1: 400, 0: 400})\n",
      "y_test distribution: Counter({0: 100, 1: 100})\n",
      "\n",
      "Class distribution in y_train (percentages): {1: 50.0, 0: 50.0}\n",
      "Class distribution in y_test (percentages): {0: 50.0, 1: 50.0}\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       100\n",
      "           1       0.93      0.91      0.92       100\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.92       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "[[93  7]\n",
      " [ 9 91]]\n",
      "Log Loss: 2.8834922711293722\n",
      "X_train size: (800, 20)\n",
      "X_test size: (200, 20)\n",
      "y_train size: (800,)\n",
      "y_test size: (200,)\n",
      "\n",
      "y_train distribution: Counter({1: 400, 0: 400})\n",
      "y_test distribution: Counter({0: 100, 1: 100})\n",
      "\n",
      "Class distribution in y_train (percentages): {1: 50.0, 0: 50.0}\n",
      "Class distribution in y_test (percentages): {0: 50.0, 1: 50.0}\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       100\n",
      "           1       0.91      0.88      0.89       100\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.89       200\n",
      "\n",
      "[[91  9]\n",
      " [12 88]]\n",
      "Log Loss: 3.7845836058573012\n",
      "X_train size: (800, 20)\n",
      "X_test size: (200, 20)\n",
      "y_train size: (800,)\n",
      "y_test size: (200,)\n",
      "\n",
      "y_train distribution: Counter({1: 400, 0: 400})\n",
      "y_test distribution: Counter({1: 100, 0: 100})\n",
      "\n",
      "Class distribution in y_train (percentages): {1: 50.0, 0: 50.0}\n",
      "Class distribution in y_test (percentages): {1: 50.0, 0: 50.0}\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       100\n",
      "           1       0.87      0.90      0.88       100\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.88      0.88       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "[[86 14]\n",
      " [10 90]]\n",
      "Log Loss: 4.325238406694059\n",
      "X_train size: (800, 20)\n",
      "X_test size: (200, 20)\n",
      "y_train size: (800,)\n",
      "y_test size: (200,)\n",
      "\n",
      "y_train distribution: Counter({1: 400, 0: 400})\n",
      "y_test distribution: Counter({0: 100, 1: 100})\n",
      "\n",
      "Class distribution in y_train (percentages): {1: 50.0, 0: 50.0}\n",
      "Class distribution in y_test (percentages): {0: 50.0, 1: 50.0}\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       100\n",
      "           1       0.91      0.85      0.88       100\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.88       200\n",
      "weighted avg       0.89      0.89      0.88       200\n",
      "\n",
      "[[92  8]\n",
      " [15 85]]\n",
      "Log Loss: 4.145020139748473\n",
      "Average Accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X2, y2):\n",
    "    X_train, X_test = X2[train_index], X2[test_index]\n",
    "    y_train, y_test = y2[train_index], y2[test_index]  \n",
    "    \n",
    "    print(\"X_train size:\", X_train.shape)\n",
    "    print(\"X_test size:\", X_test.shape)\n",
    "    print(\"y_train size:\", y_train.shape)\n",
    "    print(\"y_test size:\", y_test.shape)\n",
    "    \n",
    "    y_train_distribution = Counter(y_train)\n",
    "    y_test_distribution = Counter(y_test)\n",
    "\n",
    "    print(\"\\ny_train distribution:\", y_train_distribution)\n",
    "    print(\"y_test distribution:\", y_test_distribution)\n",
    "\n",
    "    y_train_percent = {k: v / len(y_train) * 100 for k, v in y_train_distribution.items()}\n",
    "    y_test_percent = {k: v / len(y_test) * 100 for k, v in y_test_distribution.items()}\n",
    "\n",
    "    print(\"\\nClass distribution in y_train (percentages):\", y_train_percent)\n",
    "    print(\"Class distribution in y_test (percentages):\", y_test_percent)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(f'Log Loss: {log_loss(y_test, predictions)}')\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(highest_accuracy_model, open('RF_pickled_final_df.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (688, 7)\n",
      "X_test size: (172, 7)\n",
      "y_train size: (688,)\n",
      "y_test size: (172,)\n",
      "\n",
      "y_train distribution: Counter({1: 542, 0: 146})\n",
      "y_test distribution: Counter({1: 135, 0: 37})\n",
      "\n",
      "Class distribution in y_train (percentages): {1: 78.77906976744185, 0: 21.22093023255814}\n",
      "Class distribution in y_test (percentages): {1: 78.48837209302324, 0: 21.511627906976745}\n",
      "\n",
      "\n",
      "old model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.57      0.68        37\n",
      "           1       0.89      0.97      0.93       135\n",
      "\n",
      "    accuracy                           0.88       172\n",
      "   macro avg       0.87      0.77      0.80       172\n",
      "weighted avg       0.88      0.88      0.87       172\n",
      "\n",
      "[[ 21  16]\n",
      " [  4 131]]\n",
      "4.191122487106646\n",
      "accuracy:  0.8837209302325582\n",
      "\n",
      "old default param model - not brute forced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.62      0.73        37\n",
      "           1       0.90      0.98      0.94       135\n",
      "\n",
      "    accuracy                           0.90       172\n",
      "   macro avg       0.89      0.80      0.83       172\n",
      "weighted avg       0.90      0.90      0.89       172\n",
      "\n",
      "[[ 23  14]\n",
      " [  3 132]]\n",
      "3.5624541140406487\n",
      "accuracy:  0.9011627906976745\n",
      "\n",
      "most frequent baseline model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        37\n",
      "           1       0.78      1.00      0.88       135\n",
      "\n",
      "    accuracy                           0.78       172\n",
      "   macro avg       0.39      0.50      0.44       172\n",
      "weighted avg       0.62      0.78      0.69       172\n",
      "\n",
      "[[  0  37]\n",
      " [  0 135]]\n",
      "7.7535766011472935\n",
      "accuracy:  0.7848837209302325\n",
      "\n",
      "uniform random baseline model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.46      0.29        37\n",
      "           1       0.78      0.53      0.63       135\n",
      "\n",
      "    accuracy                           0.51       172\n",
      "   macro avg       0.50      0.49      0.46       172\n",
      "weighted avg       0.66      0.51      0.56       172\n",
      "\n",
      "[[17 20]\n",
      " [64 71]]\n",
      "17.602714445847912\n",
      "accuracy:  0.5116279069767442\n",
      "\n",
      "stratified random baseline model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.19      0.17        37\n",
      "           1       0.77      0.73      0.75       135\n",
      "\n",
      "    accuracy                           0.61       172\n",
      "   macro avg       0.46      0.46      0.46       172\n",
      "weighted avg       0.64      0.61      0.62       172\n",
      "\n",
      "[[ 7 30]\n",
      " [37 98]]\n",
      "14.040260331807266\n",
      "accuracy:  0.6104651162790697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing previous model and baseline models\n",
    "\n",
    "\"\"\"import os\n",
    "print(os.getcwd())\"\"\"\n",
    "test_split = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "\n",
    "print(\"X_train size:\", X_train.shape)\n",
    "print(\"X_test size:\", X_test.shape)\n",
    "print(\"y_train size:\", y_train.shape)\n",
    "print(\"y_test size:\", y_test.shape)\n",
    "\n",
    "y_train_distribution = Counter(y_train)\n",
    "y_test_distribution = Counter(y_test)\n",
    "\n",
    "print(\"\\ny_train distribution:\", y_train_distribution)\n",
    "print(\"y_test distribution:\", y_test_distribution)\n",
    "\n",
    "y_train_percent = {k: v / len(y_train) * 100 for k, v in y_train_distribution.items()}\n",
    "y_test_percent = {k: v / len(y_test) * 100 for k, v in y_test_distribution.items()}\n",
    "\n",
    "print(\"\\nClass distribution in y_train (percentages):\", y_train_percent)\n",
    "print(\"Class distribution in y_test (percentages):\", y_test_percent)\n",
    "print(\"\\n\")\n",
    "\n",
    "pickled_model = pickle.load(open('RF_pickled_final_old_df.pkl', 'rb'))\n",
    "old_predictions = pickled_model.predict(X_test)\n",
    "print(\"old model\")\n",
    "print(classification_report(y_test, old_predictions))\n",
    "print(confusion_matrix(y_test, old_predictions))\n",
    "print(log_loss(y_test, old_predictions))\n",
    "print('accuracy: ', sklearn.metrics.accuracy_score(y_test, old_predictions))\n",
    "print()\n",
    "\n",
    "pickled_model = pickle.load(open('RF_pickled_final_old_df_defaultParam.pkl', 'rb'))\n",
    "old_predictions = pickled_model.predict(X_test)\n",
    "print(\"old default param model - not brute forced\")\n",
    "print(classification_report(y_test, old_predictions))\n",
    "print(confusion_matrix(y_test, old_predictions))\n",
    "print(log_loss(y_test, old_predictions))\n",
    "print('accuracy: ', sklearn.metrics.accuracy_score(y_test, old_predictions))\n",
    "print()\n",
    "\n",
    "mostFreqBaseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "mostFreqBaseline.fit(X_train, y_train)\n",
    "mostFreqBaselinePred = mostFreqBaseline.predict(X_test)\n",
    "print(\"most frequent baseline model\")\n",
    "print(classification_report(y_test, mostFreqBaselinePred, zero_division=0))\n",
    "print(confusion_matrix(y_test, mostFreqBaselinePred))\n",
    "print(log_loss(y_test, mostFreqBaselinePred))\n",
    "print('accuracy: ', sklearn.metrics.accuracy_score(y_test, mostFreqBaselinePred))\n",
    "print()\n",
    "\n",
    "uniformBaseline = DummyClassifier(strategy=\"uniform\")\n",
    "uniformBaseline.fit(X_train, y_train)\n",
    "uniformBaselinePred = uniformBaseline.predict(X_test)\n",
    "print(\"uniform random baseline model\")\n",
    "print(classification_report(y_test, uniformBaselinePred))\n",
    "print(confusion_matrix(y_test, uniformBaselinePred))\n",
    "print(log_loss(y_test, uniformBaselinePred))\n",
    "print('accuracy: ', sklearn.metrics.accuracy_score(y_test, uniformBaselinePred))\n",
    "print()\n",
    "\n",
    "stratifiedBaseline = DummyClassifier(strategy=\"stratified\")\n",
    "stratifiedBaseline.fit(X_train, y_train)\n",
    "stratifiedBaselinePred = stratifiedBaseline.predict(X_test)\n",
    "print(\"stratified random baseline model\")\n",
    "print(classification_report(y_test, stratifiedBaselinePred))\n",
    "print(confusion_matrix(y_test, stratifiedBaselinePred))\n",
    "print(log_loss(y_test, stratifiedBaselinePred))\n",
    "print('accuracy: ', sklearn.metrics.accuracy_score(y_test, stratifiedBaselinePred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81        37\n",
      "           1       0.92      0.99      0.96       135\n",
      "\n",
      "    accuracy                           0.93       172\n",
      "   macro avg       0.94      0.85      0.88       172\n",
      "weighted avg       0.93      0.93      0.93       172\n",
      "\n",
      "[[ 26  11]\n",
      " [  1 134]]\n",
      "2.5146734922639875\n",
      "accuracy:  0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "pickled_model = pickle.load(open('RF_pickled_final_df.pkl', 'rb'))\n",
    "new_predictions = pickled_model.predict(X_test)\n",
    "print(classification_report(y_test, new_predictions))\n",
    "print(confusion_matrix(y_test, new_predictions))\n",
    "print(log_loss(y_test, new_predictions))\n",
    "print('accuracy: ', sklearn.metrics.accuracy_score(new_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75        14\n",
      "           1       0.95      0.99      0.97       102\n",
      "\n",
      "    accuracy                           0.95       116\n",
      "   macro avg       0.93      0.82      0.86       116\n",
      "weighted avg       0.95      0.95      0.94       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(best_y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.64        48\n",
      "           1       0.89      0.92      0.90       170\n",
      "\n",
      "    accuracy                           0.85       218\n",
      "   macro avg       0.78      0.76      0.77       218\n",
      "weighted avg       0.84      0.85      0.85       218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "# model = RandomForestClassifier(n_estimators=6)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indox\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\indox\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\indox\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\indox\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      1.00      0.90        94\n",
      "\n",
      "    accuracy                           0.81       116\n",
      "   macro avg       0.41      0.50      0.45       116\n",
      "weighted avg       0.66      0.81      0.73       116\n",
      "\n",
      "[[ 0 22]\n",
      " [ 0 94]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44        18\n",
      "           1       0.89      0.97      0.93        98\n",
      "\n",
      "    accuracy                           0.87       116\n",
      "   macro avg       0.78      0.65      0.69       116\n",
      "weighted avg       0.85      0.87      0.85       116\n",
      "\n",
      "[[ 6 12]\n",
      " [ 3 95]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.40      0.52        15\n",
      "           1       0.92      0.98      0.95       101\n",
      "\n",
      "    accuracy                           0.91       116\n",
      "   macro avg       0.83      0.69      0.73       116\n",
      "weighted avg       0.90      0.91      0.89       116\n",
      "\n",
      "[[ 6  9]\n",
      " [ 2 99]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64        15\n",
      "           1       0.93      1.00      0.96       101\n",
      "\n",
      "    accuracy                           0.93       116\n",
      "   macro avg       0.96      0.73      0.80       116\n",
      "weighted avg       0.94      0.93      0.92       116\n",
      "\n",
      "[[  7   8]\n",
      " [  0 101]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81        19\n",
      "           1       0.94      1.00      0.97        97\n",
      "\n",
      "    accuracy                           0.95       116\n",
      "   macro avg       0.97      0.84      0.89       116\n",
      "weighted avg       0.95      0.95      0.94       116\n",
      "\n",
      "[[13  6]\n",
      " [ 0 97]]\n",
      "\n",
      "\n",
      "0.9482758620689655\n",
      "0.970873786407767\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "max_accuracy = -1\n",
    "highest_accuracy_model = None\n",
    "balanced_accuracy = -1\n",
    "best_predictions = None\n",
    "\n",
    "test_split_ll = 0.15\n",
    "test_split_ul = 0.50\n",
    "test_split = test_split_ll\n",
    "best_y_test = None\n",
    "\n",
    "while test_split <= test_split_ul:\n",
    "    for i in range(1, 201):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "        #model = RandomForestClassifier(n_estimators=i)\n",
    "        model = XGBClassifier(n_estimators=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        if sklearn.metrics.accuracy_score(predictions, y_test) > max_accuracy:\n",
    "            max_accuracy = sklearn.metrics.accuracy_score(predictions, y_test)\n",
    "            balanced_accuracy = max(balanced_accuracy, balanced_accuracy_score(predictions, y_test))\n",
    "            highest_accuracy_model = model\n",
    "            best_predictions = predictions\n",
    "            best_y_test = y_test\n",
    "            print(classification_report(y_test, predictions))\n",
    "            print(confusion_matrix(y_test, predictions))\n",
    "            print()\n",
    "            print()\n",
    "    \n",
    "    test_split += 0.1\n",
    "        \n",
    "print(max_accuracy)\n",
    "print(balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
